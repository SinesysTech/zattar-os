# Deploy do Sinesys

Este documento descreve como fazer o deploy da stack Sinesys em diferentes ambientes.

## Arquitetura de Servi√ßos

O Sinesys √© composto por **3 servi√ßos independentes**, cada um em seu pr√≥prio reposit√≥rio:

| Servi√ßo | Reposit√≥rio | Descri√ß√£o | Porta | WebSocket |
|---------|-------------|-----------|-------|-----------|
| **sinesys_app** | Este repo | Frontend Next.js + API | 3000 | ‚ùå |
| **sinesys_mcp** | sinesys-mcp-server | MCP Server para agentes IA | 3001 | ‚ùå |
| **sinesys_browser** | sinesys-browser-server | Firefox (scraping PJE) | 3000 | ‚úÖ |

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Servidor                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ   ‚îÇ  sinesys_app ‚îÇ   ‚îÇ sinesys_mcp  ‚îÇ   ‚îÇsinesys_browser‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  (Next.js)   ‚îÇ   ‚îÇ  (Node.js)   ‚îÇ   ‚îÇ   (Firefox)   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  :3000       ‚îÇ   ‚îÇ  :3001       ‚îÇ   ‚îÇ  :3000 (WS)   ‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ          ‚îÇ                  ‚îÇ                    ‚îÇ           ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                             ‚îÇ                                ‚îÇ
‚îÇ                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                     ‚îÇ   Supabase    ‚îÇ                       ‚îÇ
‚îÇ                     ‚îÇ Redis MongoDB ‚îÇ                       ‚îÇ
‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Deploy no CapRover

### Pr√©-requisitos

- CapRover instalado e configurado
- CLI do CapRover (`npm install -g caprover`)
- Acesso ao dashboard do CapRover
- Os 3 reposit√≥rios clonados localmente

### Passo 1: Criar os Apps no CapRover

Acesse o dashboard do CapRover e crie **3 apps**:

| Nome do App | Reposit√≥rio | HTTP Port | WebSocket |
|-------------|-------------|-----------|-----------|
| `sinesys` | Este repo | 3000 | ‚ùå |
| `sinesys-mcp` | sinesys-mcp-server | 3001 | ‚ùå |
| `sinesys-browser` | sinesys-browser-server | 3000 | ‚úÖ |

> ‚ö†Ô∏è **Importante**: Habilite WebSocket Support apenas para `sinesys-browser`!

### Passo 2: Deploy do Browser Service (Firefox)

**No reposit√≥rio sinesys-browser-server:**

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-org/sinesys-browser-server.git
cd sinesys-browser-server

# Login no CapRover
caprover login

# Deploy
caprover deploy -a sinesys-browser
```

**Vari√°veis de ambiente:**
```env
PORT=3000
BROWSER_TOKEN=seu_token_opcional
```

**Configura√ß√µes importantes:**
- Container HTTP Port: `3000`
- WebSocket Support: ‚úÖ **Habilitar**
- Memory: 2048MB (m√≠nimo)

### Passo 3: Deploy do MCP Server

**No reposit√≥rio sinesys-mcp-server:**

```bash
cd sinesys-mcp-server

# Login no CapRover (se ainda n√£o fez)
caprover login

# Deploy
caprover deploy -a sinesys-mcp
```

**Vari√°veis de ambiente:**
```env
NODE_ENV=production
PORT=3001
SINESYS_API_URL=http://srv-captain--sinesys:3000
SINESYS_API_KEY=sua_api_key
```

### Passo 4: Deploy do App Principal

**Neste reposit√≥rio (Sinesys):**

```bash
# Login no CapRover
caprover login

# Deploy
caprover deploy -a sinesys
```

> **Importante**: O CapRover pedir√° os build args. Informe:
> - `NEXT_PUBLIC_SUPABASE_URL`
> - `NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY`
> ‚ö†Ô∏è Importante: Antes de configurar deploy, leia a se√ß√£o 'Prevenindo M√∫ltiplos Builds Simult√¢neos' para evitar problemas.
> üí° **Dica**: Para entender como otimizar o tempo de build, veja a se√ß√£o "Otimiza√ß√£o de Build e Cache Docker".
> üí° **Nota**: O build do Next.js requer pelo menos 4GB de RAM dispon√≠vel no servidor. Verifique a se√ß√£o "Prote√ß√µes Contra Out-Of-Memory (OOM)" para detalhes.
> üí° **Nota**: Para entender os scripts de build, veja 'Scripts de Build e Configura√ß√£o do Next.js'.

**Vari√°veis de ambiente:**
```env
NODE_ENV=production
NEXT_TELEMETRY_DISABLED=1
PORT=3000
HOSTNAME=0.0.0.0

# Supabase
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY=sua_anon_key
SUPABASE_SECRET_KEY=sua_secret_key

# Browser Service (comunica√ß√£o interna CapRover)
BROWSER_WS_ENDPOINT=ws://srv-captain--sinesys-browser:3000
BROWSER_SERVICE_URL=http://srv-captain--sinesys-browser:3000

# Redis (opcional)
ENABLE_REDIS_CACHE=true
REDIS_URL=redis://host:port

# MongoDB (opcional)
MONGODB_URL=mongodb://...
MONGODB_DATABASE=sinesys
```

### Passo 5: Configurar Dom√≠nios e HTTPS

No dashboard do CapRover:

| App | Dom√≠nio | HTTPS |
|-----|---------|-------|
| sinesys | app.seudominio.com.br | ‚úÖ |
| sinesys-mcp | mcp.seudominio.com.br (opcional) | ‚úÖ |
| sinesys-browser | (n√£o expor) | ‚Äî |

---

## Deploy com Docker Compose (Local)

Para desenvolvimento local, voc√™ pode usar o `docker-compose.yml` simplificado:

```bash
# Subir apenas o app (sem mcp e browser)
docker-compose up -d

# Ver logs
docker-compose logs -f

# Parar
docker-compose down
```

> **Nota**: Para desenvolvimento completo com os 3 servi√ßos, clone os outros reposit√≥rios e suba-os separadamente.

---

## Comunica√ß√£o entre Servi√ßos

### No CapRover
Use o formato: `srv-captain--NOME_DO_APP`

```
http://srv-captain--sinesys:3000
http://srv-captain--sinesys-mcp:3001
ws://srv-captain--sinesys-browser:3000
```

### No Docker Compose Local
Use o nome do servi√ßo:

```
http://sinesys_app:3000
```

---

## Scripts de Build e Configura√ß√£o do Next.js

#### Diferen√ßa entre Scripts de Build

O projeto possui diferentes scripts de build para diferentes cen√°rios:

| Script | Comando | Uso | Turbopack | Otimiza√ß√µes |
|--------|---------|-----|-----------|-------------|
| `build:prod` | `next build --webpack` | **Produ√ß√£o (CapRover)** | ‚ùå N√£o | M√°ximas |
| `build` | `next build --turbopack` + filtros | Desenvolvimento local | ‚úÖ Sim | Warnings filtrados |
| `build:prod:webpack` | `next build --webpack` | Fallback se Turbopack falhar | ‚ùå N√£o | M√°ximas |
| `build:prod:turbopack` | `next build --turbopack` | Produ√ß√£o (experimental) | ‚úÖ Sim | Experimental |
| `build:debug-memory` | `node scripts/run-build-debug-memory.js` | Debug de OOM | ‚úÖ Sim | + GC trace |
| `analyze` | `node scripts/run-analyze.js` | An√°lise de bundle | ‚úÖ Sim | + Analyzer |

**Por que Webpack em produ√ß√£o?**
- O plugin PWA `@ducanh2912/next-pwa` requer Webpack para gerar corretamente o service worker e assets offline.
- Garante compatibilidade total com a configura√ß√£o `withPWA(...)` em `next.config.ts`.
- Turbopack permanece dispon√≠vel para desenvolvimento local e experimentos, mas n√£o √© usado no caminho principal de produ√ß√£o.

**Quando usar Webpack?**
- Se houver problemas de compatibilidade com Turbopack
- Se usar plugins Webpack customizados n√£o suportados
- Use o script `build:prod:webpack` como fallback

#### Otimiza√ß√µes de Mem√≥ria no next.config.ts

O `next.config.ts` inclui v√°rias otimiza√ß√µes para reduzir consumo de mem√≥ria:

**1. Source Maps desabilitados:**
```typescript
productionBrowserSourceMaps: false,  // Economiza ~500MB durante build
experimental: {
  serverSourceMaps: false,           // Reduz mem√≥ria do servidor
}
```

**2. Otimiza√ß√µes de Webpack:**
```typescript
experimental: {
  webpackMemoryOptimizations: true,  // Reduz uso de mem√≥ria durante build
  webpackBuildWorker: true,          // Usa worker separado para build
}
```

**3. Output Standalone:**
```typescript
output: 'standalone',  // Gera build otimizado para Docker (~200-300MB)
```

**Trade-offs:**
- `webpackMemoryOptimizations: true` pode aumentar tempo de build em ~10-20%
- Source maps desabilitados dificultam debug em produ√ß√£o (use logs estruturados)
- `typescript.ignoreBuildErrors: true` **esconde erros de tipo** - use com cautela

#### An√°lise de Bundle

Para identificar depend√™ncias grandes que consomem mem√≥ria:

```bash
# Gerar relat√≥rio de an√°lise
npm run analyze

# Abrir relat√≥rios gerados
open analyze/client.html
open analyze/server.html
```

**O que procurar:**
- Depend√™ncias >500KB que podem ser otimizadas
- Bibliotecas duplicadas (diferentes vers√µes)
- C√≥digo n√£o usado (tree-shaking incompleto)

**A√ß√µes comuns:**
- Substituir bibliotecas grandes por alternativas menores
- Usar imports din√¢micos para c√≥digo n√£o-cr√≠tico
- Atualizar depend√™ncias para vers√µes mais leves

#### Debug de Mem√≥ria

Se o build falhar com OOM, use o script de debug:

```bash
npm run build:debug-memory
```

Este script:
- Define `NODE_OPTIONS` com `--max-old-space-size=2048` e `--trace-gc`
- Mostra eventos de garbage collection durante o build
- Ajuda a identificar picos de mem√≥ria e poss√≠veis vazamentos

**Analisando heap snapshots:**
```bash
# Gerar heap profile
node --heap-prof node_modules/next/dist/bin/next build

# Abrir no Chrome DevTools
# 1. Abra chrome://inspect
# 2. Clique em "Open dedicated DevTools for Node"
# 3. V√° para Memory tab
# 4. Load o arquivo .heapprofile gerado
```

#### TypeScript Build Errors

O projeto usa `typescript.ignoreBuildErrors: true` no `next.config.ts`.

**Por qu√™?**
- [DOCUMENTAR RAZ√ÉO ESPEC√çFICA DO PROJETO]
- Permite builds mesmo com erros de tipo
- √ötil durante desenvolvimento r√°pido

**Riscos:**
- Erros de tipo podem causar bugs em produ√ß√£o
- Dificulta manuten√ß√£o do c√≥digo
- Pode esconder problemas s√©rios

**Alternativas mais seguras:**
```bash
# Verificar tipos antes do build (recomendado)
npm run type-check

# Build com verifica√ß√£o de tipos
# Remover temporariamente ignoreBuildErrors do next.config.ts
```

**Recomenda√ß√£o**: Considere remover `ignoreBuildErrors` e corrigir erros de tipo gradualmente.

---

## Build Args vs Environment Variables

### Build Args (tempo de build)
Usados apenas durante `docker build`:
- `NEXT_PUBLIC_SUPABASE_URL`
- `NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY`

> **Por qu√™?** Vari√°veis `NEXT_PUBLIC_*` s√£o "inlined" no c√≥digo durante o build do Next.js.

### Environment Variables (runtime)
Usadas quando o container est√° rodando:
- `SUPABASE_SECRET_KEY`
- `BROWSER_WS_ENDPOINT`
- `REDIS_URL`
- etc.

---

## Troubleshooting

### Build falha com OOM (Out of Memory)

O Next.js pode consumir muita mem√≥ria durante o build. Solu√ß√µes r√°pidas:

1. **Aumentar mem√≥ria do build no CapRover**:
   - App Configs > Build Timeout & Memory
   - Aumente para 4096MB ou mais

2. **Usar swap no servidor**:
   ```bash
   sudo fallocate -l 4G /swapfile
   sudo chmod 600 /swapfile
   sudo mkswap /swapfile
   sudo swapon /swapfile
   ```

3. **Build em m√°quina externa**:
   ```bash
   docker build -t sinesys:latest .
   docker tag sinesys:latest seu-registry/sinesys:latest
   docker push seu-registry/sinesys:latest
   ```
   E no CapRover, use "Deploy via ImageName".
   üí° Dica: Se o OOM ocorre durante m√∫ltiplos builds simult√¢neos, veja a se√ß√£o 'Prevenindo M√∫ltiplos Builds Simult√¢neos'.
   üí° **Nota**: Builds simult√¢neos consomem mais mem√≥ria. Veja "Prevenindo M√∫ltiplos Builds Simult√¢neos" e "Otimiza√ß√£o de Build e Cache Docker".
   üí° Para prote√ß√µes abrangentes contra OOM, veja a se√ß√£o 'Prote√ß√µes Contra Out-Of-Memory (OOM)'.
   üí° **Dica**: Use `npm run build:debug-memory` para diagnosticar problemas. Veja 'Scripts de Build e Configura√ß√£o do Next.js' para detalhes.

### Container reinicia constantemente

Verifique os logs no dashboard do CapRover: App > App Logs

### Browser Service n√£o conecta

1. Verifique se o app `sinesys-browser` est√° rodando
2. Confirme que **WebSocket est√° habilitado** no app
3. Teste a conex√£o:
   ```bash
   curl http://srv-captain--sinesys-browser:3000/health
   ```

## Otimiza√ß√£o de Build e Cache Docker

### Como o Cache Docker Funciona

Docker cria **layers** para cada comando no Dockerfile. Cada layer √© uma imagem intermedi√°ria que √© armazenada em cache. Quando voc√™ executa um build, o Docker verifica se o comando e o contexto (arquivos copiados) mudaram desde o √∫ltimo build. Se n√£o mudaram, a layer √© reutilizada, economizando tempo.

Mudan√ßas em arquivos invalidam o cache de comandos subsequentes. Por exemplo, se voc√™ muda um arquivo no `COPY . .`, todas as layers depois dessa ser√£o recriadas.

**Exemplo visual de otimiza√ß√£o de cache:**
```
# Sem otimiza√ß√£o (ruim):
COPY . .          # Copia tudo primeiro
RUN npm ci        # Sempre roda se qualquer arquivo mudar

# Com otimiza√ß√£o (bom):
COPY package.json .  # Copia apenas package.json
RUN npm ci           # S√≥ roda se package.json mudar
COPY . .             # Copia resto dos arquivos
```

### Estrat√©gia de Cache no Sinesys

O Dockerfile do Sinesys usa uma estrutura **multi-stage** (deps ‚Üí builder ‚Üí runner) para otimizar o cache:

- **Stage `deps`**: Cache de depend√™ncias (reutilizado se `package.json` n√£o mudar)
- **Stage `builder`**: Cache de build (invalidado se c√≥digo mudar)
- **Stage `runner`**: Imagem final leve (~200-300MB)

O `.dockerignore` reduz o contexto de build de ~1.2GB para ~100MB, evitando que arquivos desnecess√°rios invalidem o cache.

### Impacto de Mudan√ßas no Cache

| Mudan√ßa | Layers invalidadas | Tempo estimado |
|---------|-------------------|----------------|
| `package.json` | deps + builder + runner | ~3-5min |
| C√≥digo-fonte | builder + runner | ~2-3min |
| Build args | builder + runner | ~2-3min |
| `.dockerignore` | tudo | ~3-5min |

**Dica**: Evite mudar `package.json` e c√≥digo no mesmo commit se poss√≠vel.

### Otimizando Tempo de Build

- **Dica 1**: Fa√ßa commits at√¥micos (uma mudan√ßa por vez)
- **Dica 2**: Evite mudar arquivos desnecess√°rios (use `.dockerignore`)
- **Dica 3**: Agrupe mudan√ßas em `package.json` em commits separados
- **Dica 4**: Use build local para testar antes de push (evita builds desnecess√°rios no servidor)
- **Dica 5**: Considere usar Docker BuildKit para cache distribu√≠do

### Verificando Uso de Cache

Para identificar se o cache est√° sendo usado, leia os logs do Docker:

- **Cache hit**: `---> Using cache`
- **Cache miss**: `---> Running in ...`

**Exemplo de log com cache:**
```
Step 4/12 : COPY package.json package-lock.json* ./
 ---> Using cache
Step 5/12 : RUN npm ci --ignore-scripts
 ---> Using cache
Step 6/12 : COPY --from=deps /app/node_modules ./node_modules
 ---> Using cache
```

**Calculando tempo economizado**: Compare o tempo total do build com/sem cache. Tipicamente, builds com cache completo levam ~1-2min vs ~4-6min sem cache.

### Troubleshooting de Cache

**Problema**: Build sempre demora mesmo sem mudan√ßas
- **Causa**: `.dockerignore` pode estar incorreto, incluindo arquivos tempor√°rios que mudam sempre
- **Solu√ß√£o**: Verificar se arquivos como `.next`, `node_modules` ou logs est√£o sendo exclu√≠dos

**Problema**: Cache n√£o √© reutilizado ap√≥s mudan√ßa pequena
- **Causa**: Mudan√ßa em arquivo que afeta uma layer anterior (ex: mudar `README.md` invalida `COPY . .`)
- **Solu√ß√£o**: Revisar ordem de comandos no Dockerfile ou mover arquivos n√£o-essenciais para fora do contexto
üí° **Nota**: Para otimiza√ß√µes do Next.js, veja 'Scripts de Build e Configura√ß√£o do Next.js'.

---

## Prote√ß√µes Contra Out-Of-Memory (OOM)

### Introdu√ß√£o

Erros de Out-Of-Memory (OOM) ocorrem quando o Next.js build consome mais mem√≥ria RAM do que est√° dispon√≠vel no servidor. Um build t√≠pico do Next.js pode usar ~2-3GB de RAM, especialmente em projetos com muitas p√°ginas ou componentes complexos. Quando m√∫ltiplos builds ocorrem simultaneamente (devido a webhooks duplicados), o consumo pode multiplicar, causando falhas.

### Requisitos de Mem√≥ria

| Cen√°rio | RAM M√≠nima | RAM Recomendada | Notas |
|---------|------------|-----------------|-------|
| Build √∫nico | 4GB | 6GB | Inclui 2GB para Node.js + 2GB para sistema |
| Build com cache | 3GB | 4GB | Builds subsequentes consomem menos |
| M√∫ltiplos builds simult√¢neos | 4GB √ó n√∫mero de builds | 6GB √ó n√∫mero de builds | Evite builds simult√¢neos |

O `NODE_OPTIONS="--max-old-space-size=2048"` no Dockerfile limita o heap do Node.js a 2GB. O sistema operacional precisa de ~1-2GB adicionais para opera√ß√µes normais.

### Configura√ß√µes do CapRover

#### Build Memory
Acesse App Configs ‚Üí Build Timeout & Memory para ajustar:
- **Valor recomendado**: 4096MB (m√≠nimo para builds est√°veis)
- **Valor ideal**: 6144MB ou 8192MB para builds mais r√°pidos e projetos grandes

#### Build Timeout
Recomenda√ß√µes baseadas no cen√°rio:
- **Build sem cache**: 600s (10 minutos) - primeira vez ou ap√≥s mudan√ßas em depend√™ncias
- **Build com cache**: 300s (5 minutos) - builds subsequentes
- **Build com depend√™ncias novas**: 900s (15 minutos) - quando `package.json` muda

#### Instance Count
Mantenha em 1 durante o build para evitar m√∫ltiplas inst√¢ncias consumindo mem√≥ria extra.

### Configura√ß√£o de Swap (Servidores com RAM Limitada)

Use swap quando o servidor tiver menos de 4GB RAM. O swap permite que o sistema use disco como mem√≥ria adicional, mas torna os builds 2-3x mais lentos.

#### Quando usar swap
- Servidores com <4GB RAM f√≠sica
- Builds espor√°dicos (n√£o produ√ß√£o cont√≠nua)

#### Impacto no desempenho
- Builds ficam 2-3x mais lentos devido ao acesso ao disco
- Alto uso de swap (>50%) pode causar travamentos do sistema

#### Comandos para configurar swap
```bash
# Criar arquivo de swap de 4GB
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# Tornar permanente (adicionar ao /etc/fstab)
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab

# Verificar swap ativo
sudo swapon --show
free -h
```

#### Otimizar uso de swap
```bash
# Reduzir swappiness para usar swap apenas quando necess√°rio
sudo sysctl vm.swappiness=10
echo 'vm.swappiness=10' | sudo tee -a /etc/sysctl.conf
```

### Script de Verifica√ß√£o Pr√©-Build

Use o script `scripts/check-build-memory.sh` para verificar mem√≥ria dispon√≠vel antes do build:

```bash
# Verificar mem√≥ria dispon√≠vel antes do build
bash scripts/check-build-memory.sh
```

O script verifica:
- Mem√≥ria RAM dispon√≠vel
- Swap dispon√≠vel
- Processos que consomem muita mem√≥ria
- Recomenda√ß√µes baseadas no estado atual

### Troubleshooting de Erros OOM

#### Sintoma 1: Build falha com "JavaScript heap out of memory"
- **Causa**: Node.js atingiu o limite de mem√≥ria (padr√£o 2GB)
- **Solu√ß√£o**: Aumentar `NODE_OPTIONS` no Dockerfile (ex: `--max-old-space-size=4096`) ou mem√≥ria do CapRover

#### Sintoma 2: Container √© killed durante build (exit code 137)
- **Causa**: Sistema operacional matou o processo por falta de mem√≥ria
- **Solu√ß√£o**: Adicionar swap ou aumentar RAM f√≠sica do servidor

#### Sintoma 3: Build demora muito e servidor fica lento
- **Causa**: Uso excessivo de swap (>50%)
- **Solu√ß√£o**: Aumentar RAM f√≠sica ou otimizar build para consumir menos mem√≥ria

#### Sintoma 4: M√∫ltiplos builds simult√¢neos causam OOM
- **Causa**: Webhooks duplicados ou configura√ß√£o de auto-deploy + webhook
- **Solu√ß√£o**: Ver se√ß√£o "Prevenindo M√∫ltiplos Builds Simult√¢neos"

#### Diagn√≥stico via logs
- **CapRover logs**: Procure por "out of memory", "heap", "killed"
- **Comandos de diagn√≥stico**:
  ```bash
  # Ver uso de mem√≥ria em tempo real
  free -h
  
  # Ver processos que mais consomem mem√≥ria
  ps aux --sort=-%mem | head -n 10
  
  # Ver logs do sistema sobre OOM
  sudo dmesg | grep -i "out of memory"
  ```

### Alternativas para Servidores com Pouca Mem√≥ria

#### Op√ß√£o 1: Build em m√°quina externa
Use GitHub Actions ou m√°quina local para build e push da imagem:

```yaml
# .github/workflows/build-and-deploy.yml
name: Build and Deploy to CapRover
on:
  push:
    branches: [main]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Build Docker image
        run: docker build -t sinesys:latest .
      - name: Push to registry
        run: |
          docker tag sinesys:latest registry.example.com/sinesys:latest
          docker push registry.example.com/sinesys:latest
      - name: Deploy to CapRover
        run: |
          caprover deploy --imageName registry.example.com/sinesys:latest
```

#### Op√ß√£o 2: Usar CapRover em servidor maior temporariamente
Migre temporariamente para um servidor com mais RAM durante builds.

#### Op√ß√£o 3: Otimizar build para consumir menos mem√≥ria
- Desabilitar source maps em produ√ß√£o
- Usar `experimental.cpus` no `next.config.ts` para limitar paralelismo
- Considerar build incremental com ferramentas como Turborepo

### Monitoramento de Mem√≥ria

Configure alertas no CapRover para uso de mem√≥ria alto. Ferramentas recomendadas:
- **Netdata**: Monitoramento em tempo real
- **Prometheus + Grafana**: Dashboards customizados

M√©tricas importantes:
- Uso de RAM durante build
- Uso de swap
- Tempo de build
- N√∫mero de builds simult√¢neos

---

## Prevenindo M√∫ltiplos Builds Simult√¢neos

M√∫ltiplos builds simult√¢neos podem causar **Out of Memory (OOM)** no servidor, especialmente quando cada build consome ~2GB de RAM. Isso acontece quando webhooks duplicados ou configura√ß√µes incorretas no CapRover triggeram builds em paralelo.

### Diagn√≥stico de Webhooks Duplicados

Para identificar webhooks duplicados no GitHub:

1. Acesse o reposit√≥rio no GitHub
2. V√° para **Settings ‚Üí Webhooks**
3. Verifique a lista de webhooks ativos
4. Procure por m√∫ltiplos webhooks apontando para a mesma URL do CapRover

**Como identificar duplicados:**
- Mesmo **Payload URL** (ex: `https://captain.yourdomain.com/api/v2/user/apps/webhooks/trigger`)
- Mesmo **Content type** e **Secret** (se aplic√°vel)
- Webhooks com status "Active" para o mesmo app

**Comando para listar webhooks via GitHub CLI:**
```bash
gh api repos/{owner}/{repo}/hooks
```

> ‚ö†Ô∏è **Importante**: Cada app no CapRover deve ter apenas **uma URL de webhook ativa** no GitHub. M√∫ltiplos webhooks para o mesmo app causam builds simult√¢neos.

### Configura√ß√£o Correta no CapRover

O CapRover oferece duas op√ß√µes principais para deploy autom√°tico: **"Deploy via GitHub"** e **"Deploy Triggers (Webhook)"**. A diferen√ßa √©:

- **Deploy via GitHub**: O CapRover monitora o reposit√≥rio diretamente (requer credenciais Git configuradas)
- **Deploy Triggers (Webhook)**: Usa webhooks externos (como do GitHub) para triggerar builds

**Op√ß√£o A (Recomendada): Usar apenas "Deploy Triggers (Webhook)" do CapRover**
- No dashboard do CapRover: Apps ‚Üí [seu-app] ‚Üí Deployment ‚Üí Desabilitar "Deploy via GitHub"
- No GitHub: Configure apenas **1 webhook** com a URL fornecida pelo CapRover (Deployment ‚Üí Deploy Triggers ‚Üí Copy Webhook URL)

**Op√ß√£o B: Usar apenas "Deploy via GitHub" (sem webhook externo)**
- No GitHub: Remova todos os webhooks relacionados ao CapRover
- No CapRover: Configure credenciais Git (Deployment ‚Üí Deploy via GitHub) e habilite o monitoramento

> üö´ **NUNCA use ambos simultaneamente** (Deploy via GitHub + Webhook): Isso causa builds duplicados e simult√¢neos, levando a OOM.

### Verifica√ß√£o de Configura√ß√£o Atual

Para verificar a configura√ß√£o atual no CapRover:

1. Acesse o dashboard: Apps ‚Üí [seu-app] ‚Üí Deployment
2. Verifique se "Deploy via GitHub" est√° habilitado
3. Verifique se h√° webhook configurado em "Deploy Triggers"
4. Se ambos estiverem ativos, **desabilite um deles** (recomendado: mantenha apenas o webhook)

### Boas Pr√°ticas para Deploy

- Fa√ßa commits at√¥micos: Evite m√∫ltiplos pushes em sequ√™ncia r√°pida
- Aguarde a conclus√£o do build anterior antes de fazer novo push
- Use `git push --force` com cautela: Pode triggerar m√∫ltiplos builds se houver conflitos
- Considere usar branches de staging para testes antes de deploy em produ√ß√£o

### Checklist de Verifica√ß√£o Pr√©-Deploy

Antes de cada deploy, verifique:

- [ ] Existe apenas **1 webhook ativo** no GitHub para este app
- [ ] Apenas **uma op√ß√£o de deploy** est√° habilitada no CapRover (webhook OU auto-deploy)
- [ ] N√£o h√° builds em andamento antes de fazer push
- [ ] O servidor tem mem√≥ria suficiente (m√≠nimo 4GB dispon√≠vel)

### Troubleshooting de M√∫ltiplos Builds

**Sintoma**: Logs mostram "A build for [app] was queued, it's now being replaced with a new build..." ou builds simult√¢neos causando OOM.

**Diagn√≥stico**:
- No GitHub: Settings ‚Üí Webhooks ‚Üí Recent Deliveries ‚Üí Procure m√∫ltiplas requisi√ß√µes para o mesmo commit SHA
- No CapRover: Verifique logs do app para identificar origem dos triggers (webhook vs auto-deploy)

**Solu√ß√£o**:
- Remova webhooks duplicados no GitHub
- Desabilite auto-deploy se estiver usando webhook manual
- Aumente mem√≥ria do servidor ou adicione swap (ver se√ß√£o "Build falha com OOM")

### Exemplo de Configura√ß√£o Correta

```
‚úÖ CONFIGURA√á√ÉO RECOMENDADA:
- GitHub: 1 webhook ativo (URL do CapRover)
- CapRover: Deploy Triggers habilitado
- CapRover: Deploy via GitHub DESABILITADO

‚ùå CONFIGURA√á√ÉO INCORRETA (causa m√∫ltiplos builds):
- GitHub: 2+ webhooks ativos
- CapRover: Deploy Triggers E Deploy via GitHub ambos habilitados
```

---

## Recursos Recomendados

| Servi√ßo | RAM M√≠nima (Runtime) | RAM Recomendada (Runtime) | RAM para Build | CPU |
|---------|----------------------|---------------------------|----------------|-----|
| sinesys_app | 512MB | 1GB | 4GB (m√≠nimo) | 1 core |
| sinesys_mcp | 128MB | 256MB | N/A | 0.5 core |
| sinesys_browser | 1GB | 2GB | N/A | 1-2 cores |

**Total recomendado para runtime**: VPS com 4GB RAM, 2-4 cores  
**Total recomendado para build**: Pelo menos 4GB RAM adicional dispon√≠vel durante builds

---

## Vari√°veis de Ambiente Completas

### App Principal (sinesys)

```env
# Supabase (obrigat√≥rio)
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY=eyJ...
SUPABASE_SECRET_KEY=eyJ...

# API Key (para comunica√ß√£o entre servi√ßos)
SERVICE_API_KEY=sua_api_key_segura

# Browser Service
BROWSER_WS_ENDPOINT=ws://srv-captain--sinesys-browser:3000
BROWSER_SERVICE_URL=http://srv-captain--sinesys-browser:3000
BROWSER_SERVICE_TOKEN=opcional_token_seguranca

# Redis (opcional)
ENABLE_REDIS_CACHE=true
REDIS_URL=redis://user:password@host:6379

# MongoDB (opcional)
MONGODB_URL=mongodb://user:password@host:27017
MONGODB_DATABASE=sinesys

# 2FAuth (para OTP do PJE)
TWOFAUTH_API_URL=https://seu-2fauth.com
TWOFAUTH_API_TOKEN=seu_token
TWOFAUTH_ACCOUNT_ID=id_da_conta
```

### MCP Server (sinesys-mcp)

```env
NODE_ENV=production
PORT=3001
SINESYS_API_URL=http://srv-captain--sinesys:3000
SINESYS_API_KEY=sua_api_key_segura
```

### Browser Server (sinesys-browser)

```env
PORT=3000
BROWSER_TOKEN=opcional_token_seguranca
